{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import  torch\n",
    "\n",
    "import sys\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# setting path\n",
    "sys.path.append('~/pubmedQA_291')\n",
    "from dataset import MedMCQA_Datamodule\n",
    "from model import MedMCQAModel\n",
    "from show_attention import generate\n",
    "config = {\n",
    "    \"contrastive\": False,\n",
    "    \"has_additional_prompt\":False,\n",
    "    \"pretrained_model\":\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\",\n",
    "    \"num_workers\": 8,\n",
    "    \"bs\":32,\n",
    "    \"lr\":2e-5,\n",
    "    \"attention_dropout\" : 0.1,\n",
    "    \"hidden_dropout\" : 0.1,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"model_style\": \"classification\",\n",
    "    \"output_attentions\": True\n",
    "}\n",
    "dm = MedMCQA_Datamodule(batch_size=64, parser_args=config)\n",
    "model = MedMCQAModel(parser_args=config, **config)\n",
    "path_finetuned_pubmed_bert = '/root/pubmedQA_291/exps/prevent_overfitting/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert/checkpoints/epoch=2-step=4287.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "                        max_epochs=1,\n",
    "                        accelerator=\"gpu\",\n",
    "                        \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /root/pubmedQA_291/exps/prevent_overfitting/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert/checkpoints/epoch=2-step=4287.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /root/pubmedQA_291/exps/prevent_overfitting/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert/checkpoints/epoch=2-step=4287.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 66/66 [00:14<00:00,  4.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val/ce_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.4994843006134033     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/mean_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42690834403038025    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val/ce_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.4994843006134033    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/mean_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42690834403038025   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val/ce_loss': 1.4994843006134033, 'val/mean_acc': 0.42690834403038025}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer.validate(model, dm, ckpt_path=path_finetuned_pubmed_bert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config['has_additional_prompt'] = True\n",
    "dm_hints = MedMCQA_Datamodule(batch_size=64, parser_args=config)\n",
    "model_hints = MedMCQAModel(parser_args=config, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /root/pubmedQA_291/exps/prevent_overfitting/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert/checkpoints/epoch=2-step=4287.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /root/pubmedQA_291/exps/prevent_overfitting/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert/checkpoints/epoch=2-step=4287.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 66/66 [00:17<00:00,  3.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val/ce_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.5857653617858887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/mean_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3806612491607666     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val/ce_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5857653617858887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/mean_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3806612491607666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val/ce_loss': 1.5857653617858887, 'val/mean_acc': 0.3806612491607666}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model_hints, dm_hints, ckpt_path=path_finetuned_pubmed_bert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_contrastive_model = '/root/pubmedQA_291/exps/contrastive/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert_contrastive_finetuning_small_lr/checkpoints/epoch=0-step=1429.ckpt'\n",
    "config['contrastive'] = True\n",
    "config['contrastive_coeff']=0.1 \n",
    "config['has_additional_prompt'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Restoring states from the checkpoint path at /root/pubmedQA_291/exps/contrastive/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert_contrastive_finetuning_small_lr/checkpoints/epoch=0-step=1429.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /root/pubmedQA_291/exps/contrastive/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert_contrastive_finetuning_small_lr/checkpoints/epoch=0-step=1429.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 66/66 [00:13<00:00,  4.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val/ce_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.8113086223602295     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/mean_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4288022816181183     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val/ce_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8113086223602295    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/mean_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4288022816181183    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val/ce_loss': 1.8113086223602295, 'val/mean_acc': 0.4288022816181183}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrastive model, no hints\n",
    "\n",
    "\n",
    "dm_contrastive = MedMCQA_Datamodule(batch_size=64, parser_args=config)\n",
    "model_contrastive = MedMCQAModel(parser_args=config, **config)\n",
    "trainer.validate(model_contrastive, dm_contrastive, ckpt_path=path_contrastive_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Restoring states from the checkpoint path at /root/pubmedQA_291/exps/contrastive/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert_contrastive_finetuning_small_lr/checkpoints/epoch=0-step=1429.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /root/pubmedQA_291/exps/contrastive/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert_contrastive_finetuning_small_lr/checkpoints/epoch=0-step=1429.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 66/66 [00:17<00:00,  3.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val/ce_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.8931595087051392     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/mean_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3915822505950928     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val/ce_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8931595087051392    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/mean_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3915822505950928    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val/ce_loss': 1.8931595087051392, 'val/mean_acc': 0.3915822505950928}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['has_additional_prompt'] = True\n",
    "\n",
    "dm_contrastive_w_hints = MedMCQA_Datamodule(batch_size=64, parser_args=config)\n",
    "model_contrastive_w_hints = MedMCQAModel(parser_args=config, **config)\n",
    "trainer.validate(model_contrastive_w_hints, dm_contrastive_w_hints, ckpt_path=path_contrastive_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "# dm_hints.setup()\n",
    "# val_loader = dm_hints.val_dataloader()\n",
    "path_contrastive_model = '/root/pubmedQA_291/exps/contrastive/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext_classification/pubmed_bert_contrastive/checkpoints/epoch=6-step=10003.ckpt'\n",
    "config['contrastive'] = True\n",
    "config['contrastive_coeff']=0.1 \n",
    "config['has_additional_prompt'] = False\n",
    "\n",
    "\n",
    "dm_contrastive = MedMCQA_Datamodule(batch_size=1, parser_args=config)\n",
    "model_contrastive = MedMCQAModel(parser_args=config, **config)\n",
    "\n",
    "dm_contrastive.setup()\n",
    "val_loader = dm_contrastive.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'[CLS]', '[MASK]', '[PAD]', '[SEP]', '[UNK]'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= MedMCQAModel.load_from_checkpoint(checkpoint_path=path_contrastive_model, parser_args=config)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(config['pretrained_model'])\n",
    "special_tokens = set(tokenizer.all_special_tokens)\n",
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labl: tensor([2]), pred: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ite, batch in enumerate(val_loader):\n",
    "    \n",
    "    if ite<2: continue\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "    # inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "    outputs = model(input_ids, attention_mask, output_hidden_states=True)  # Run model\n",
    "    pred =  torch.argmax(outputs.logits, dim=1)\n",
    "    print(f\"labl: {labels}, pred: {pred}\")\n",
    "    attention = outputs.attentions  # Retrieve attention from model outputs\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])  # Convert input ids to token strings\n",
    "    \n",
    "    attention_sum = sum(attention[0:6])[:,:,0].sum(dim=(0,1)) # Sum the attention weights across heads in first layers\n",
    "    # attention_sum = attention[-1][:,:,0].sum(dim=(0,1)) # Sum the attention weights across heads in first layers\n",
    "    \n",
    "    # if ite==10:\n",
    "    #     break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_to_show = torch.clip(attention_sum*30, 0 ,100).tolist()\n",
    "texts_and_attention_weights = [(tokens[i],attention_to_show[i]) for i  in range(len(tokens)) if tokens[i] not in special_tokens]\n",
    "texts, attention_weights_for_text = zip(*texts_and_attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(texts, attention_weights_for_text, \"no_hint.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'subject',\n",
       " ':',\n",
       " 'medicine',\n",
       " ',',\n",
       " 'topic',\n",
       " ':',\n",
       " 'none',\n",
       " 'question',\n",
       " ':',\n",
       " 'a',\n",
       " '29',\n",
       " 'yrs',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'with',\n",
       " 'a',\n",
       " 'pregnancy',\n",
       " 'of',\n",
       " '17',\n",
       " 'week',\n",
       " 'has',\n",
       " 'a',\n",
       " '10',\n",
       " 'years',\n",
       " 'old',\n",
       " 'boy',\n",
       " 'with',\n",
       " 'down',\n",
       " 'syndrome',\n",
       " '.',\n",
       " 'she',\n",
       " 'does',\n",
       " 'not',\n",
       " 'want',\n",
       " 'another',\n",
       " 'down',\n",
       " 'syndrome',\n",
       " 'kid',\n",
       " ';',\n",
       " 'best',\n",
       " 'advice',\n",
       " 'to',\n",
       " 'her',\n",
       " 'is',\n",
       " 'a',\n",
       " ':',\n",
       " 'no',\n",
       " 'test',\n",
       " 'is',\n",
       " 'required',\n",
       " 'now',\n",
       " 'as',\n",
       " 'her',\n",
       " 'age',\n",
       " 'is',\n",
       " 'below',\n",
       " '35',\n",
       " 'years',\n",
       " 'b',\n",
       " ':',\n",
       " 'ultra',\n",
       " 'sound',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'of',\n",
       " 'time',\n",
       " 'will',\n",
       " 'definitely',\n",
       " 'tell',\n",
       " 'her',\n",
       " 'that',\n",
       " 'next',\n",
       " 'baby',\n",
       " 'will',\n",
       " 'be',\n",
       " 'down',\n",
       " 'syndromic',\n",
       " 'or',\n",
       " 'not',\n",
       " 'c',\n",
       " ':',\n",
       " 'amniotic',\n",
       " 'fluid',\n",
       " 'samples',\n",
       " 'plus',\n",
       " 'chromosomal',\n",
       " 'analysis',\n",
       " 'will',\n",
       " 'definitely',\n",
       " 'tell',\n",
       " 'her',\n",
       " 'that',\n",
       " 'next',\n",
       " 'baby',\n",
       " 'will',\n",
       " 'be',\n",
       " 'down',\n",
       " 'syndromic',\n",
       " 'or',\n",
       " 'not',\n",
       " 'd',\n",
       " ':',\n",
       " 'blood',\n",
       " 'screening',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'of',\n",
       " 'time',\n",
       " 'will',\n",
       " 'clear',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'picture',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['has_additional_prompt'] = True\n",
    "dm_contrastive_hints = MedMCQA_Datamodule(batch_size=1, parser_args=config)\n",
    "dm_contrastive_hints.setup()\n",
    "val_loader_hints = dm_contrastive_hints.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labl: tensor([2]), pred: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ite, batch in enumerate(val_loader_hints):\n",
    "    if ite<2: continue\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "    # inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "    outputs = model(input_ids, attention_mask, output_hidden_states=True)  # Run model\n",
    "    print(f\"labl: {labels}, pred: {pred}\")\n",
    "    # if labels.item()!=pred:\n",
    "    #    continue\n",
    "    attention = outputs.attentions  # Retrieve attention from model outputs\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])  # Convert input ids to token strings\n",
    "    \n",
    "    pred =  torch.argmax(outputs.logits, dim=1)\n",
    "    # bad = False\n",
    "    # for t in tokens:\n",
    "    #     if \"#\" in t:\n",
    "    #         bad = True\n",
    "    #         break\n",
    "    # if bad:\n",
    "    #     continue\n",
    "    \n",
    "    attention_sum = sum(attention)[:,:,0].sum(dim=(0,1)) # Sum the attention weights across heads in first layers\n",
    "    \n",
    "    break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_to_show = torch.clip(attention_sum*30, 0 ,100).tolist()\n",
    "texts_and_attention_weights = [(tokens[i],attention_to_show[i]) for i  in range(len(tokens)) if tokens[i] not in special_tokens]\n",
    "texts, attention_weights_for_text = zip(*texts_and_attention_weights)\n",
    "generate(texts, attention_weights_for_text, \"with_hint.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'subject',\n",
       " ':',\n",
       " 'pediatrics',\n",
       " ',',\n",
       " 'topic',\n",
       " ':',\n",
       " 'none',\n",
       " 'question',\n",
       " ':',\n",
       " 'given',\n",
       " 'a',\n",
       " 'retrospective',\n",
       " 'study',\n",
       " ',',\n",
       " 'sequential',\n",
       " 'arrangement',\n",
       " 'of',\n",
       " 'fetal',\n",
       " 'scans',\n",
       " '-',\n",
       " 'a',\n",
       " ':',\n",
       " 'growth',\n",
       " 'scan',\n",
       " 'b',\n",
       " ':',\n",
       " 'triple',\n",
       " 'marker',\n",
       " 'c',\n",
       " ':',\n",
       " 'anomalous',\n",
       " 'scan',\n",
       " 'and',\n",
       " 'nt',\n",
       " 'scan',\n",
       " 'd',\n",
       " ':',\n",
       " 'all',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
